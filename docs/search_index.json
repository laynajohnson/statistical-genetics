[["index.html", "Statistical Genetics Content Summary Introduction", " Statistical Genetics Content Summary Alayna Johnson 2025-03-20 Introduction In the following chapters, you will find concepts and examples related to statistical genetics explained. This breakdown is more directed towards those who are familiar with RStudio coding and statistical concepts, but who may not be as familiar with genetics or biology. You will learn different terms and methodologies in statistical genetics. Note that this site does not have all ideas and methods related to statistical genetics. This is only a small start, and there is much more to explore. "],["genome-wide-association-studies-gwas.html", " 1 Genome-Wide Association Studies (GWAS) 1.1 Introduction to GWAS 1.2 Simulating a GWAS 1.3 Marginal Regression 1.4 Visualizing GWAS Wrapping up", " 1 Genome-Wide Association Studies (GWAS) Some Vocabulary There are many terms that come along with talking about genetic data. The following are some more biology (genetics) related terms to remember as you read this unit summary. Refer to this list if you forget what a term means. SNPs (single nucleotide polymorphisms): a single nucleotide at a specific position in the genome, genetic variant at least 1% frequent in the population Genome: complete set of genes or genetic material Chromosome: condensed DNA structure, all chromosomes together is the genome Genetic variants: positions where DNA sequences differ SNV (single nucleotide variant): a single nucleotide change in the DNA sequence. SNP and SNV are typically used interchangeably. You might see SNP used in instances where the minor allele is not too rare Allele: the different possible nucleotides at some position. The combinations are A - T and G - C Minor allele: at this location, which allele is the least common MAF (minor allele frequency): the frequency of the minor allele, can get very small Loci/locus: means location, can be used to refer to a single SNP or a larger region in the genome 1.1 Introduction to GWAS When looking at human DNA, we can see that between any two people, their genomes would be almost exactly identical. However, there are places where their DNA sequences differ. These are called genetic variants. Sometimes these variants mean nothing, other times they have been found to be linked to certain traits or health problems. The goal of a genome-wide association study (GWAS), is to determine which genetic variants are associated with a given trait of interest. 1.1.1 Genome Breakdown Before getting too far into GWAS, let’s take a moment to dive into some of the science-y details. I created a series of images that break down some of the different vocabulary from above and how they are related. Most humans have 23 pairs of chromosomes. Within each pair, you have one chromosome given from each parent. The chromosome for parent 1 is made up of a mixture of DNA from both of that parent’s parents and likewise for the chromosome for parent 2. We can also see that each chromosome is actually just an X-ish shape of DNA all bundled up. When we “unwrap” it, we can see some more levels of terms to remember. Figure 1.1: 23 pairs of chromosomes from parents (left) and Chromosome unwound DNA (right) These next two drawings show how the segments of DNA creates an individual’s genes and the nucleotides and alleles inside that create a genetic variant. So, within each long strand of DNA wrapped into the chromosome, there are segments that give us certain traits. These are called genes. The DNA and their genes are made up of four different nucleotide base pairs in between the sugar-phosphate backbone of the DNA (the outside lines). The four nucleotide bases are: adenine (A), thymine (T), cytosine (C), and guanine (G). In the vocab section, I mentioned that these are called alleles and they have specific pairings. A will always be with T just as C will always be with G. We can see in these visualizations that we can zoom into some segement of DNA and see a SNV where there are two possible alleles. This is called biallelic. Figure 1.2: Some gene segment from DNA sequence (left) and genetic variant (right) Now that we can better understand some genomic structures, let’s get back into explaining GWAS. 1.1.2 A small example Below is an example of a small study of alleles that can be different at some place along the DNA sequence. We can call this a biallelic genetic variant. The goal of this GWAS study is to see if the pairings of alleles at certain positions have some effect on the trait. We know from before that A and T pair as well as C and G. This means we really only need to list one nucleotide base in our data given the other is known. person ID parent 1 allele parent 2 allele trait 10005 A A 60 10006 A G 67 10007 G A 68 10008 A A 62 Instead of having this more complex table, if we know G is the minor allele in this position we can recode the table. Instead of two columns for A and G, we can have one column combining the two where G is 1 and A is 0. It doesn’t matter the order anyways, so this transformation is fine. Here is what that would look like: person ID alleles trait 10005 0 60 10006 1 67 10007 1 68 10008 0 62 The typical GWAS model looks like this. Think about what would go into the variables below from our small example. \\[ E[y \\mid x] = \\beta_0 + \\beta_1 x \\] We are able to use this model easily as our data has only one position of interest, or SNP. But what happens when we have a data set where there are more columns than there are rows, \\((p&gt;n)\\)? The answer here is that we run into an issue of big data. We must have the same or more observations as we do coefficients in order to effectively run a regression model. When we have too many coefficients and not a sufficient number of observations, we will get NA values. The DNA sequence of a single person consists of an estimated 3 billion nucleotides. While a GWAS will not typically measure every single position, they can still be hundreds of thousands to billions of columns. The “study” we did above was a very reduced example of what a GWAS could look like. So, how can we estimate the effect of some genetic variant on our trait of interest if we cannot use one giant regression model? 1.2 Simulating a GWAS Using the rbinom function, we can randomly generate data from a binomial distribution. We choose a size of \\(n = 100\\) people and a probability of having the minor allele as \\(p = 0.1\\). The last argument in the function tells us the number of trials, or in this case, each person is randomly assigned to have either 0, 1, or 2 minor alleles. set.seed(494) # for reproducible random number generation snp &lt;- rbinom(n = 100, size = 2, p = 0.1) # 100 people, MAF = 0.1 print(snp) ## [1] 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 ## [28] 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [55] 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 ## [82] 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 We know from before that we actually would see way more than just one genetic variant for \\(n\\) number of people. So, we can extend the above rbinom function into our own function in which we can choose the number of genetic variants to simulate per person # function doing the same as the one before, where we get to choose the number of people in the study and the minor allele frequency (MAF) do_one &lt;- function(n_ppl, MAF){ snp &lt;- rbinom(n = n_ppl, size = 2, p = MAF) return(snp) } # combining the previous function with the `replicate` function to replicate 1000 times to create 1000 variants set.seed(494) snps &lt;- replicate(1000, do_one(n_ppl = 100, MAF = 0.1)) This new snps object has 100 people each with 1000 variants. We can use the functions nrow and ncol to see that data is \\((p&gt;n)\\). nrow(snps) ## [1] 100 ncol(snps) ## [1] 1000 Now, we can create some numeric trait using the rnorm function and combine the data with our SNPs from before using cbind. set.seed(494) # set seed for reproducibility y &lt;- rnorm(100, mean = 65, sd = 3) # generate trait print(y) ## [1] 59.62481 63.88034 63.02679 62.50892 70.83525 67.50514 ## [7] 63.61816 69.64214 64.97347 65.47989 63.13887 63.07716 ## [13] 63.74931 64.70136 65.07071 58.33367 61.91952 64.85250 ## [19] 65.66969 62.40541 62.04025 61.84794 64.28388 65.04385 ## [25] 61.42188 62.55285 59.29327 67.46579 61.65637 67.67236 ## [31] 66.09086 70.02120 68.01750 60.73839 58.42093 67.99430 ## [37] 65.89968 64.39152 65.65709 66.54789 65.00309 65.34142 ## [43] 63.41219 68.68026 61.68235 61.18094 68.73800 69.94243 ## [49] 66.55700 60.87955 66.43440 56.08365 69.62706 68.09680 ## [55] 68.85878 64.92834 63.05479 65.98005 64.87043 64.69823 ## [61] 65.76869 67.50849 65.20761 62.59497 68.12195 67.62197 ## [67] 66.63407 66.00194 62.77750 63.89318 63.51581 71.79953 ## [73] 65.50906 68.08233 68.99696 64.76795 69.99623 66.88639 ## [79] 65.01119 65.69350 64.53200 64.69204 65.19411 64.11513 ## [85] 63.19411 62.63277 62.99986 64.56554 67.31328 62.24985 ## [91] 65.15231 61.25394 67.23057 65.94068 64.43938 69.38935 ## [97] 66.89983 65.07994 63.90870 60.93687 # creating a single data frame for snps and trait dat &lt;- as.data.frame(cbind(y, snps)) With our SNPs and trait data together, we can perform a simulated GWAS study. But, we need another tool to help us solve this \\((p&gt;n)\\) problem that occurs from trying to use one giant regression model. This will be explained next. 1.3 Marginal Regression For the extent of this text, we will not be performing an actual GWAS study with real data. However, we will explain the idea of marginal regression and what it has to do with data that is \\((p&gt;n)\\). With our simulation in the last section, if we were to try to fit a multiple linear regression model with the data we would get NA values for many of the coefficients. We cannot estimate more coefficients than we have observations. For our simulation this means that we cannot fit this model as there are 100 observations (people) and 1000 variants (coefficients). Marginal regression is a technique of dealing with \\((p&gt;n)\\) data. We can fit individual models for each variant and check which are significantly related with our trait of interest. \\[ \\begin{align} E[y \\mid x_j] = \\beta_0 + \\beta_{1j} x_j, \\qquad y &amp;= \\text{trait of interest}\\\\ x_j &amp;= \\text{number of minor alleles at position }j \\end{align} \\] The model above represents what one marginal regression model looks like. We would repeatedly fit a model like this for all positions \\(j = 1, 2, \\dots m\\). To find out if our SNPs are associated with our trait of interest, we also perform hypothesis testing for each model. For each model, our null hypothesis, \\(H_0\\), is that there is no relationship between the genetic variant and our trait of interest. This means the alternative, \\(H_A\\), is that there is a relationship present. Using our example from before, say we fit 1000 models and perform 1000 hypothesis tests. When performing just one test, we would typically use a significance threshold of \\(\\alpha = 0.05\\), or, \\(p&lt;0.05\\). As a reminder, we choose a value for \\(\\alpha\\) based on how “comfortable” we are with making a type 1 error. A type 1 error happens when we reject \\(H_0\\) and say there is a relationship between the SNP and trait of interest. If we only conduct one hypothesis test, this means the probability of making a type 1 error is \\(P(\\text{T1E}) = 0.05\\). As we increase the number of tests, the probability of making at least one type 1 error increases. But we are not actually comfortable with concluding there is a relationship when there is truly not one so many times. This is the idea of multiple testing. There are many ways to adjust for this by making our significance threshold smaller. 1.3.1 Multiple testing One way to adjust for multiple testing is to use the Bonferroni Correction. Say we still want the probability of at least one type 1 error at less than 5% with the 1000 tests we would have to perform with our simulation data. We can find this significance threshold by dividing the probability by the number of hypothesis tests we performed. This makes the significance threshold pretty small (\\(5 \\ast 10^{-5}\\)). But a typical GWAS will involve hundreds of thousands or even billions of SNPs. So our threshold can get pretty tiny for this many hypothesis tests (e.g. \\(5 \\ast 10^{-11}\\)). However, this might be too conservative and lead us to make type 2 errors. This means that our threshold might actually be too small which could lead us to not reject the null when we should have (found no association where we should have). We could also adjust for multiple testing by using a simulation-based approach. This solution is way more computationally expensive than a Bonferroni Correction. Steps to this process can look something like this: Simulate a null trait (i.e., a trait that is not associated with any of the SNPs) Run GWAS to test the association between this simulated null trait and each of the SNPs in our dataset. Record the smallest p-value from this GWAS. Repeat steps 1–3 many (e.g., 100, 1000) times. Look at the p-values you saved from those simulation replicates. Sort them from smallest to largest and find the lowest 5th percentile (i.e., the point at which 5% of the p-values are smaller than that number). The positives of this approach is that our p-value threshold will most likely be less conservative than if we used the Bonferroni Correction instead. 1.4 Visualizing GWAS Since our studies may have many many SNPs to test significance for, it can be hard to visualize. If we just take and plot our p-values vs each SNP’s position in a scatter plot, it won’t look very nice. There are too many values crowing around each other. Visualizing data always helps, and there is a fix for this issue. We can create a Manhattan Plot with the manhattan() function in the qqman package to visualize our significance results. Below is an image of an example Manhattan plot to give an idea of what our p-values look like for each SNP. Figure 1.3: Manhattan plot example Another type of visualization we can use as a diagnostic tool are called QQ plots. These plots allow us to compare the results from our study to what we would see if no SNPs were associated with our disease of interest. We would expect that not all of the SNPs in our study are associated with the trait, so most should fall on the \\(y = x\\) line. If there are some SNPs that we find are associated with the trait of interest, we would visually see some points above the diagonal \\(y = x\\). Figure 1.4: QQ plot example Wrapping up With that, we have come to the end of this chapter on genome-wide association studies (GWAS). You now have many of the concepts you need to understand this methodology and attempt to perform some studies yourself. "],["genetic-ancestry.html", " 2 Genetic Ancestry 2.1 Describing Human Populations 2.2 Principal Component Analysis 2.3 Omitted Variable Bias", " 2 Genetic Ancestry Some Vocabulary 2.1 Describing Human Populations 2.1.1 Population Admixture 2.2 Principal Component Analysis 2.3 Omitted Variable Bias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
